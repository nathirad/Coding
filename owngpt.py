# -*- coding: utf-8 -*-
"""OwnGPT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19y9DvOwkzZryVwwfg6nsEyJjwCgvWnX5

# Setup Environment

ติดตั้ง Library ต่างๆที่จำเป็นกับ Chatbot ของเรารวมถึงเซ็ตอัพค่าต่างๆ
"""

!pip install -q langchain chainlit openai faiss-cpu tiktoken
!npm install -g localtunnel

# Commented out IPython magic to ensure Python compatibility.
# %env OPENAI_API_KEY="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"

import os
os.environ["OPENAI_API_KEY"] ="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"

"""# Build RAG Chatbot With Langchain

สร้างแชทบอตด้วย library ชื่อ Langchain ด้วยเทคนิค Retreival Augmented Generation (RAG) เพื่อใช้ในการตอบคำถามจากข้อมูลที่ให้ไป
"""

from langchain.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

# ข้อมูลมีขนาดใหญ่เราจึงแบ่งเป็น Chunk เล็กๆ เพื่อให้ความยาว Input ไม่มากจนเกินไป
text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=100)

# แหล่งที่มาของข้อมูล
websites = [
    "https://www.cp.eng.chula.ac.th/about/faculty",
    "https://www.cp.eng.chula.ac.th/future/bachelor"
]

# ทำการโหลดข้อมูลและแบ่งเป็น Chunk ที่กำหนดไว้
loader = WebBaseLoader(websites)
loader.requests_kwargs  = {"verify":False}
data = loader.load()
texts = text_splitter.split_documents(data)

# ใช้ OpenAI API ในการเข้ารหัสข้อความเป็นข้อมูล Vector แสดงค่าของประโยคหรือเอหสารที่แบ่งเป็น Chunk นั้นๆ
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")

# ทำการโหลดเว็บไซต์เข้าไปใน Vector Database (ในที่นี่เราใช้เป็น FAISS เพื่อความรวดเร็ว)
# Vector DB ได้แก่ ChromaDB, FluxDB, PostgresQL (Extension), etc..
db = FAISS.from_documents(texts, embeddings)
retriever = db.as_retriever(search_kwargs={"k":4})

from langchain.agents import Tool
from langchain.chains import RetrievalQA
from langchain.llms.openai import OpenAI
from langchain.memory import ConversationBufferMemory

# LLM (Large Language Model) คือหัวใจสำคัญของ Chatbot ที่ทำหน้าที่
# เข้าใจ และประมวลผล ภาษาในรูปแบบของตัวเลขด้วยความสัมพันธ์บางอย่าง
# In short: THIS IS AI!!
llm = OpenAI(temperature=0.0)

# Memory คือสิ่งที่สามารถใช้เก็บข้อมูลหรือประวัติการสนทนาของผู้ใช้ได้
# ใช้ในกรณีที่เราถามแชทบอทซ้ำแต่ไม่ได้เอ่ยถึงอีกรอบอย่างชัดเจน Ex. Who is P'Patrick? ... How old is he?
memory = ConversationBufferMemory(memory_key="chat_history",return_messages=True)

# Tools คือสิ่งที่ทำให้ LLM นั้นมีความฉลาด เนื่องจากเป็นที่เก็บเอกสาต่างๆ (ข้อมูลที่เราโหลดไว้ตอนแรก)
# ที่มีความสำคัญและ AI ไม่สามารถเปลี่ยนแปลงได้ เหมือน 2+2=5??? ก็เลยใช้ Tools เพื่อมาคำนวณจริงๆ ไม่ใช่มั่วๆขึ้นมา
tools = [
  Tool(
    name="DocumentSearch",
    description="This tool can search and get information. Useful for when you need to answer questions",
    # ตรงนี้เลยที่ทำให้มันฉลาดล่ะ!!
    # สามารถเปลี่ยนวิธีการหาคำตอบของมันได้ด้วยการเปลี่ยน chain_type = "stuff", "refine","map_reduce","map_rerank"
    func=RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever,return_source_documents=False).run
  ),
]

from langchain.agents import AgentExecutor
from langchain.agents import AgentType, initialize_agent

# สร้าง Chatbot เอเจ้นท์ที่สามารถใช้งาน Tools ที่แตกต่างกัน เปรียบเสมือนบุคคลคนหนึ่ง
# บางคนเก่งเลข บางคนเก่งวาดรูป ฯลฯ
agent = initialize_agent(
    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True,memory=memory,handle_parsing_errors=True
)

# ลองมาเล่นกันเลยยย
agent.run({"input": "อาจารย์คนไหนสอน pROGRAMMING บ้าง"})

agent.run({"input":"ใครคือ อ.ดร. กมลลักษณ์ สุขเสน"})

"""# Create App Interface

เรามาเริ่มสร้างหน้าต่างให้ใช้งานง่ายๆกันดีกว่า
"""

# Commented out IPython magic to ensure Python compatibility.
# # ทำการสร้างไฟล์ที่ชื่อว่า app.py เพื่อเก็บโปรแกรมของเราไว้
# %%writefile app.py
# from langchain.document_loaders import WebBaseLoader
# from langchain.text_splitter import CharacterTextSplitter
# from langchain.vectorstores import FAISS
# from langchain.embeddings import OpenAIEmbeddings
# from langchain.agents.agent_toolkits import create_retriever_tool
# from langchain.llms.openai import OpenAI
# from langchain.memory import ConversationBufferMemory
# from langchain import hub
# from langchain.agents.format_scratchpad import format_log_to_str
# from langchain.agents.output_parsers import ReActSingleInputOutputParser
# from langchain.tools.render import render_text_description
# from langchain.agents import AgentType, initialize_agent, Tool
# from langchain.chains import RetrievalQA
# import chainlit as cl
# 
# 
# text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=100)
# 
# websites = [
#     "https://www.cp.eng.chula.ac.th/about/faculty",
#     "https://www.cp.eng.chula.ac.th/future/bachelor"
# ]
# 
# 
# # for website in websites:
# loader = WebBaseLoader(websites)
# loader.requests_kwargs  = {"verify":False}
# data = loader.load()
# texts = text_splitter.split_documents(data)
# 
# embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
# 
# db = FAISS.from_documents(texts, embeddings)
# retriever = db.as_retriever(search_kwargs={"k":4})
# 
# 
# llm = OpenAI(temperature=0,streaming=True)
# tools = [
#   Tool(
#     name="DocumentSearch",
#     description="This tool can search and information. Useful for when you need to answer questions",
#     func=RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever,return_source_documents=False).run
#   ),
# ]
# 
# @cl.on_chat_start
# def start():
#     memory = ConversationBufferMemory(memory_key="chat_history")
#     agent = initialize_agent(
#         tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True,memory=memory,handle_parsing_errors=True
#     )
#     return cl.user_session.set("agent",agent)
# 
# 
# @cl.on_message
# async def main(message):
#     agent = cl.user_session.get("agent")  # type: AgentExecutor
#     cb = cl.LangchainCallbackHandler(stream_final_answer=True,answer_prefix_tokens=["Final Answer: ", "I now know the final answer"])
#     cb.answer_reached = True
# 
#     await cl.make_async(agent)(message.content, callbacks=[cb])
#

# Run application ได้เลยย
!chainlit run app.py &>/content/logs.txt &
!curl ipv4.icanhazip.com
!lt --port 8000

# Constructed By PatrickChoDev :3