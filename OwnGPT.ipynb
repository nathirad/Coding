{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6fRb_Wu1k1b"
      },
      "source": [
        "# Setup Environment\n",
        "\n",
        "ติดตั้ง Library ต่างๆที่จำเป็นกับ Chatbot ของเรารวมถึงเซ็ตอัพค่าต่างๆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1x8dc9_pXca",
        "outputId": "4b6b68f2-e7d3-44e4-e8d2-4af8852ba106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 1.028s\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain chainlit openai faiss-cpu tiktoken\n",
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc0dyQ5SpZzr",
        "outputId": "430bda79-b354-4167-ab6a-afc22ac49a32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: OPENAI_API_KEY=\"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\"\n"
          ]
        }
      ],
      "source": [
        "%env OPENAI_API_KEY=\"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5DVS3zSsN8y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] =\"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGJUxZoJ1vNp"
      },
      "source": [
        "# Build RAG Chatbot With Langchain\n",
        "\n",
        "สร้างแชทบอตด้วย library ชื่อ Langchain ด้วยเทคนิค Retreival Augmented Generation (RAG) เพื่อใช้ในการตอบคำถามจากข้อมูลที่ให้ไป"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qSS7Gz-JBJP",
        "outputId": "6d16b6a0-7fae-4f8f-ac69-7505e8cebf48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.cp.eng.chula.ac.th'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.cp.eng.chula.ac.th'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1014, which is longer than the specified 800\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1301, which is longer than the specified 800\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 4440, which is longer than the specified 800\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1028, which is longer than the specified 800\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# ข้อมูลมีขนาดใหญ่เราจึงแบ่งเป็น Chunk เล็กๆ เพื่อให้ความยาว Input ไม่มากจนเกินไป\n",
        "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
        "\n",
        "# แหล่งที่มาของข้อมูล\n",
        "websites = [\n",
        "    \"https://www.cp.eng.chula.ac.th/about/faculty\",\n",
        "    \"https://www.cp.eng.chula.ac.th/future/bachelor\"\n",
        "]\n",
        "\n",
        "# ทำการโหลดข้อมูลและแบ่งเป็น Chunk ที่กำหนดไว้\n",
        "loader = WebBaseLoader(websites)\n",
        "loader.requests_kwargs  = {\"verify\":False}\n",
        "data = loader.load()\n",
        "texts = text_splitter.split_documents(data)\n",
        "\n",
        "# ใช้ OpenAI API ในการเข้ารหัสข้อความเป็นข้อมูล Vector แสดงค่าของประโยคหรือเอหสารที่แบ่งเป็น Chunk นั้นๆ\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# ทำการโหลดเว็บไซต์เข้าไปใน Vector Database (ในที่นี่เราใช้เป็น FAISS เพื่อความรวดเร็ว)\n",
        "# Vector DB ได้แก่ ChromaDB, FluxDB, PostgresQL (Extension), etc..\n",
        "db = FAISS.from_documents(texts, embeddings)\n",
        "retriever = db.as_retriever(search_kwargs={\"k\":4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq2CIheenuOx"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms.openai import OpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# LLM (Large Language Model) คือหัวใจสำคัญของ Chatbot ที่ทำหน้าที่\n",
        "# เข้าใจ และประมวลผล ภาษาในรูปแบบของตัวเลขด้วยความสัมพันธ์บางอย่าง\n",
        "# In short: THIS IS AI!!\n",
        "llm = OpenAI(temperature=0.0)\n",
        "\n",
        "# Memory คือสิ่งที่สามารถใช้เก็บข้อมูลหรือประวัติการสนทนาของผู้ใช้ได้\n",
        "# ใช้ในกรณีที่เราถามแชทบอทซ้ำแต่ไม่ได้เอ่ยถึงอีกรอบอย่างชัดเจน Ex. Who is P'Patrick? ... How old is he?\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)\n",
        "\n",
        "# Tools คือสิ่งที่ทำให้ LLM นั้นมีความฉลาด เนื่องจากเป็นที่เก็บเอกสาต่างๆ (ข้อมูลที่เราโหลดไว้ตอนแรก)\n",
        "# ที่มีความสำคัญและ AI ไม่สามารถเปลี่ยนแปลงได้ เหมือน 2+2=5??? ก็เลยใช้ Tools เพื่อมาคำนวณจริงๆ ไม่ใช่มั่วๆขึ้นมา\n",
        "tools = [\n",
        "  Tool(\n",
        "    name=\"DocumentSearch\",\n",
        "    description=\"This tool can search and get information. Useful for when you need to answer questions\",\n",
        "    # ตรงนี้เลยที่ทำให้มันฉลาดล่ะ!!\n",
        "    # สามารถเปลี่ยนวิธีการหาคำตอบของมันได้ด้วยการเปลี่ยน chain_type = \"stuff\", \"refine\",\"map_reduce\",\"map_rerank\"\n",
        "    func=RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever,return_source_documents=False).run\n",
        "  ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0fjeR9S6zpO"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "\n",
        "# สร้าง Chatbot เอเจ้นท์ที่สามารถใช้งาน Tools ที่แตกต่างกัน เปรียบเสมือนบุคคลคนหนึ่ง\n",
        "# บางคนเก่งเลข บางคนเก่งวาดรูป ฯลฯ\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True,memory=memory,handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "VmTCAyidN5Ra",
        "outputId": "e76195e8-86db-4f3b-8812-286458867c22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should search for a list of professors who teach programming.\n",
            "Action: DocumentSearch\n",
            "Action Input: \"professors who teach programming\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m ผศ.ดร. พิตติพล คันธวัฒน์, อ.ดร. กมลลักษณ์ สุขเสน, รศ.ดร. ธาราทิพย์ สุวรรณศาสตร์, รศ.ดร. โปรดปราน บุณยพุกกณะ\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: ผศ.ดร. พิตติพล คันธวัฒน์, อ.ดร. กมลลักษณ์ สุขเสน, รศ.ดร. ธาราทิพย์ สุวรรณศาสตร์, รศ.ดร. โปรดปราน บุณยพุกกณะ\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ผศ.ดร. พิตติพล คันธวัฒน์, อ.ดร. กมลลักษณ์ สุขเสน, รศ.ดร. ธาราทิพย์ สุวรรณศาสตร์, รศ.ดร. โปรดปราน บุณยพุกกณะ'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ลองมาเล่นกันเลยยย\n",
        "agent.run({\"input\": \"อาจารย์คนไหนสอน pROGRAMMING บ้าง\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "yXuDWAyvVai2",
        "outputId": "d8f0086c-0974-404c-8b1a-5cb318c956ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use DocumentSearch to find information about อ.ดร. กมลลักษณ์ สุขเสน\n",
            "Action: DocumentSearch\n",
            "Action Input: อ.ดร. กมลลักษณ์ สุขเสน\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m ไม่มีข้อมูลในบทความนี้เกี่ยวกับอ.ดร. กมลลักษณ์ สุขเสน กรุณาตรวจสอบในบทความอื่น หรือติดต่อภาควิชาวิศวกรรมคอมพิวเตอร์เพื่อขอข้อมูลเพิ่มเติม\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should try searching for อ.ดร. กมลลักษณ์ สุขเสน in a different article or contact the Computer Engineering department for more information.\n",
            "Action: DocumentSearch\n",
            "Action Input: อ.ดร. กมลลักษณ์ สุขเสน\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m ไม่มีข้อมูลในบทความนี้เกี่ยวกับอ.ดร. กมลลักษณ์ สุขเสน กรุณาตรวจสอบในบทความอื่น หรือติดต่อภาควิชาวิศวกรรมคอมพิวเตอร์เพื่อขอข้อมูลเพิ่มเติม\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should try searching for อ.ดร. กมลลักษณ์ สุขเสน in a different article or contact the Computer Engineering department for more information.\n",
            "Action: DocumentSearch\n",
            "Action Input: อ.ดร. กมลลักษณ์ สุขเสน\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m ไม่มีข้อมูลในบทความนี้เกี่ยวกับอ.ดร. กมลลักษณ์ สุขเสน กรุณาตรวจสอบในบทความอื่น หรือติดต่อภาควิชาวิศวกรรมคอมพิวเตอร์เพื่อขอข้อมูลเพิ่มเติม\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should try searching for อ.ดร. กมลลักษณ์ สุขเสน in a different article or contact the Computer Engineering department for more information.\n",
            "Action: DocumentSearch\n",
            "Action Input: อ.ดร. กมลลักษณ์ สุขเสน\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m ไม่มีข้อมูลในบทความนี้เกี่ยวกับอ.ดร. กมลลักษณ์ สุขเสน กรุณาตรวจสอบในบทความอื่น หรือติดต่อภาควิชาวิศวกรรมคอมพิวเตอร์เพื่อขอข้อมูลเพิ่มเติม\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: ไม่มีข้อมูลในบทความนี้เกี่ยวกับอ.ดร. กมลลักษณ์ สุขเสน กรุณาตรวจสอบในบทความอื่น หรือติดต่อภาควิชาวิศวกรรมคอมพิวเตอร์เพื่อขอข้อมูลเพิ่มเติม\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ไม่มีข้อมูลในบทความนี้เกี่ยวกับอ.ดร. กมลลักษณ์ สุขเสน กรุณาตรวจสอบในบทความอื่น หรือติดต่อภาควิชาวิศวกรรมคอมพิวเตอร์เพื่อขอข้อมูลเพิ่มเติม'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run({\"input\":\"ใครคือ อ.ดร. กมลลักษณ์ สุขเสน\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ckuvyqb1tBE"
      },
      "source": [
        "# Create App Interface\n",
        "\n",
        "เรามาเริ่มสร้างหน้าต่างให้ใช้งานง่ายๆกันดีกว่า"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AtNbbQXpcKq",
        "outputId": "d5dbefe2-4981-4950-f726-14613ba68639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "# ทำการสร้างไฟล์ที่ชื่อว่า app.py เพื่อเก็บโปรแกรมของเราไว้\n",
        "%%writefile app.py\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "from langchain.llms.openai import OpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import hub\n",
        "from langchain.agents.format_scratchpad import format_log_to_str\n",
        "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
        "from langchain.tools.render import render_text_description\n",
        "from langchain.agents import AgentType, initialize_agent, Tool\n",
        "from langchain.chains import RetrievalQA\n",
        "import chainlit as cl\n",
        "\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
        "\n",
        "websites = [\n",
        "    \"https://www.cp.eng.chula.ac.th/about/faculty\",\n",
        "    \"https://www.cp.eng.chula.ac.th/future/bachelor\"\n",
        "]\n",
        "\n",
        "\n",
        "# for website in websites:\n",
        "loader = WebBaseLoader(websites)\n",
        "loader.requests_kwargs  = {\"verify\":False}\n",
        "data = loader.load()\n",
        "texts = text_splitter.split_documents(data)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "db = FAISS.from_documents(texts, embeddings)\n",
        "retriever = db.as_retriever(search_kwargs={\"k\":4})\n",
        "\n",
        "\n",
        "llm = OpenAI(temperature=0,streaming=True)\n",
        "tools = [\n",
        "  Tool(\n",
        "    name=\"DocumentSearch\",\n",
        "    description=\"This tool can search and information. Useful for when you need to answer questions\",\n",
        "    func=RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever,return_source_documents=False).run\n",
        "  ),\n",
        "]\n",
        "\n",
        "@cl.on_chat_start\n",
        "def start():\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "    agent = initialize_agent(\n",
        "        tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True,memory=memory,handle_parsing_errors=True\n",
        "    )\n",
        "    return cl.user_session.set(\"agent\",agent)\n",
        "\n",
        "\n",
        "@cl.on_message\n",
        "async def main(message):\n",
        "    agent = cl.user_session.get(\"agent\")  # type: AgentExecutor\n",
        "    cb = cl.LangchainCallbackHandler(stream_final_answer=True,answer_prefix_tokens=[\"Final Answer: \", \"I now know the final answer\"])\n",
        "    cb.answer_reached = True\n",
        "\n",
        "    await cl.make_async(agent)(message.content, callbacks=[cb])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNyIMOkXsE9J",
        "outputId": "6212d22b-995a-484b-d4ed-25def7876521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.172.34.21\n",
            "your url is: https://red-jars-rescue.loca.lt\n"
          ]
        }
      ],
      "source": [
        "# Run application ได้เลยย\n",
        "!chainlit run app.py &>/content/logs.txt &\n",
        "!curl ipv4.icanhazip.com\n",
        "!lt --port 8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkqfVa5JK-Pa"
      },
      "outputs": [],
      "source": [
        "# Constructed By PatrickChoDev :3"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e6fRb_Wu1k1b"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}