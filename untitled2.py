# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UE2wOJOpDqplynDT9wUqFpPoIf49Hv1f
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

x=[1,2,3,4,5,6,7,8,9,10]
y=[25,35,40,42,51,60,62,72,78,90]
plt.scatter(x,y)

model = LinearRegression()

x = np.array(x)
y = np.array(y)
x = x.reshape(-1,1)
#print(x)
#print(y)
model.fit(x,y)
model.score(x,y)

xtest = np.linspace(0,11)

xtest = xtest.reshape(-1,1)
ytest = model.predict(xtest)
#print(xtest)
#print(ytest)
plt.scatter(x,y)
plt.plot(xtest,ytest)

"""# linear Regression"""

xtest = np.linspace(0,11)

xtest = xtest.reshape(-1,1)
ytest = model.predict(xtest)

plt.scatter(x,y)
plt.plot(x,y)

# Import necessary libraries
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
import matplotlib.pyplot as plt

# Generate synthetic data for demonstration
np.random.seed(42)
X = np.random.rand(100, 1)
y = (X > 0.5).astype(int).flatten()

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a logistic regression model
model = LogisticRegression()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = metrics.accuracy_score(y_test, y_pred)
precision = metrics.precision_score(y_test, y_pred)
recall = metrics.recall_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")

# Plot the decision boundary
plt.scatter(X_test, y_test, color='black')
X_boundary = np.linspace(0, 1, 100).reshape(-1, 1)
y_boundary = model.predict_proba(X_boundary)[:, 1]
plt.plot(X_boundary, y_boundary, color='blue', linewidth=3)
plt.xlabel('Feature')
plt.ylabel('Class')
plt.title('Logistic Regression Decision Boundary')
plt.show()

import pandas as pd

from google .colab import drive
drive.mount('/content/drive')

df = pd.read_csv("drive/MyDrive/Colab Notebooks/Heart.csv")
df

df = df.drop(columns='Unnamed: 0')
df

df['ChestPain'] = df['ChestPain'].astype('category')
df['ChestPain'] = df['ChestPain'].cat.codes
df

df['ChestPain'] = df['ChestPain'].astype('category')
df['ChestPain'] = df['ChestPain'].cat.codes
df



df['Thal'] = df['Thal'].astype('category')
df['Thal'] = df['Thal'].cat.codes
df
df['AHD'] = df['AHD'].astype('category')
df['AHD'] = df['AHD'].cat.codes
df

df.isnull().sum()

df = df.dropna()
df

X = df.drop(columns = 'AHD')
X

y = df['AHD']
y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y , test_size =0.3, random_state=21)

X_train

X_test

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.fit_transform(X_test)

X_train_scaled

X_test_scaled

from sklearn.linear_model import LogisticRegression
log_reg = LogisticRegression(random_state=0).fit(X_train_scaled,y_train)
log_reg.predict(X_train_scaled)

log_reg.score(X_train_scaled,y_train)

log_reg.score(X_test_scaled,y_test)

log_reg1 = LogisticRegression(random_state = 0 , C = 1, fit_intercept=True,).fit(X_train_scaled,y_train)

log_reg1.score(X_train_scaled,y_train)

log_reg1.score(X_test_scaled,y_test)

"""# ส่วนใหม่"""

from sklearn.datasets import load_iris
iris = load_iris()
print(iris.feature_names)
print(iris.target_names)
print(iris.data[0])

for i in range(len(iris.target)):
  print("Ex",i, ": label",iris.target[i], " feature", iris.data[i])

"""# TEST DATASET"""

test_idx = [0, 50, 100]
import numpy as np
train_target = np.delete(iris.target, test_idx)
train_data = np.delete(iris.data, test_idx, axis=0)

test_target = iris.target[test_idx]
test_data = iris.data[test_idx]

"""# Train Model

"""

from sklearn import tree
clf = tree.DecisionTreeClassifier()
clf.fit(train_data, train_target)

print(test_target)
print(clf.predict(test_data))

"""# Visualization"""

import matplotlib.pyplot as plt
tree.plot_tree(clf.fit(iris.data, iris.target))
plt.show()

"""# KNN-Predict whether a person will have diabetes or not"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score

from google.colab import drive
drive.mount('/content/drive')
dataset =  pd.read_csv('drive/MyDrive/Colab Notebooks/diabetes.csv')

len(dataset)
dataset.head()

zero_not_accepted = ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'Insulin']

for column in zero_not_accepted:
  dataset[column] = dataset[column].replace(0,np.NaN)
  mean = int(dataset[column].mean(skipna= True))
  dataset[column] = dataset[column].replace(np.NaN, mean)

X = dataset.iloc[:, 0:8]
y = dataset.iloc[:, 8]
X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0, test_size=0.2)

print(len(X_train))
print(len(y_train))
print(len(X_test))
print(len(y_test))

sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

classifier = KNeighborsClassifier(n_neighbors=11, p=2,metric='euclidean')

classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
y_pred

cm = confusion_matrix(y_test, y_pred)
print(cm)
print(f1_score(y_test, y_pred))

print(accuracy_score(y_test, y_pred))

import pandas as pd

from google .colab import drive
drive.mount('/content/drive')

df = pd.read_csv("drive/MyDrive/Colab Notebooks/Copy of gladiator_data.csv")
df

y = df.iloc[:, 23:29]
df.head()
print(y)

df = df.drop(columns='Origin')
df = df.drop(columns='Crowd Appeal Techniques')
df = df.drop(columns='Social Standing')
df

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
import matplotlib.pyplot as plt

df['Weapon of Choice'] = df['Weapon of Choice'].astype('category')
df['Weapon of Choice'] = df['Weapon of Choice'].cat.codes
df['Tactical Knowledge'] = df['Tactical Knowledge'].astype('category')
df['Tactical Knowledge'] = df['Tactical Knowledge'].cat.codes
df['Special Skills'] = df['Special Skills'].astype('category')
df['Special Skills'] = df['Special Skills'].cat.codes
df

df.isnull().sum()

df = df.dropna()
df

from sklearn.linear_model import LogisticRegression
log_reg = LogisticRegression(random_state=0).fit(X_train_scaled,y_train)
log_reg.predict(X_train_scaled)

import cv2
import numpy as np

CLASSES = ["Airpods", "Khaopun x kim", "Ipad air 4","Ipad air 3"]
cap = cv2.VideoCapture(0)
while True:
  ret, frame = cap.read()

  cv2.imshow("frame", frame)
  if cv2.waitkey

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ultralytics/yolov5  # clone
# %cd /content/yolov5
# %pip install -qr requirements.txt comet_ml  # install

import torch
import utils
display = utils.notebook_init()  # checks

!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images
# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)

!python train.py --img 640 --batch 16 --epochs 3 --data dog.yaml --weights yolov5s.pt --cache

torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)
!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip

!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images